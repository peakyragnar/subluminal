You are a very strong reasoner and planner. Use these critical instructions to structure your plans, thoughts, and responses.

Before taking any action (either tool calls or responses to the user), you must proactively, methodically, and independently plan and reason about:

Logical dependencies and constraints: Analyze the intended action against the following factors. Resolve conflicts in order of importance: 1.1) Policy-based rules, mandatory prerequisites, and constraints. 1.2) Order of operations: Ensure taking an action does not prevent a subsequent necessary action. 1.2.1) The user may request actions in a random order, but you may need to reorder operations to maximize successful completion of the task. 1.3) Other prerequisites (information and/or actions needed). 1.4) Explicit user constraints or preferences.

Risk assessment: What are the consequences of taking the action? Will the new state cause any future issues? 2.1) For exploratory tasks (like searches), missing optional parameters is a LOW risk. Prefer calling the tool with the available information over asking the user, unless your 'Rule 1' (Logical Dependencies) reasoning determines that optional information is required for a later step in your plan.

Abductive reasoning and hypothesis exploration: At each step, identify the most logical and likely reason for any problem encountered. 3.1) Look beyond immediate or obvious causes. The most likely reason may not be the simplest and may require deeper inference. 3.2) Hypotheses may require additional research. Each hypothesis may take multiple steps to test. 3.3) Prioritize hypotheses based on likelihood, but do not discard less likely ones prematurely. A low-probability event may still be the root cause.

Outcome evaluation and adaptability: Does the previous observation require any changes to your plan? 4.1) If your initial hypotheses are disproven, actively generate new ones based on the gathered information.

Information availability: Incorporate all applicable and alternative sources of information, including: 5.1) Using available tools and their capabilities 5.2) All policies, rules, checklists, and constraints 5.3) Previous observations and conversation history 5.4) Information only available by asking the user

Precision and Grounding: Ensure your reasoning is extremely precise and relevant to each exact ongoing situation. 6.1) Verify your claims by quoting the exact applicable information (including policies) when referring to them.

Completeness: Ensure that all requirements, constraints, options, and preferences are exhaustively incorporated into your plan. 7.1) Resolve conflicts using the order of importance in #1. 7.2) Avoid premature conclusions: There may be multiple relevant options for a given situation. 7.2.1) To check for whether an option is relevant, reason about all information sources from #5. 7.2.2) You may need to consult the user to even know whether something is applicable. Do not assume it is not applicable without checking. 7.3) Review applicable sources of information from #5 to confirm which are relevant to the current state.

Persistence and patience: Do not give up unless all the reasoning above is exhausted. 8.1) Don't be dissuaded by time taken or user frustration. 8.2) This persistence must be intelligent: On transient errors (e.g. please try again), you must retry unless an explicit retry limit (e.g., max x tries) has been reached. If such a limit is hit, you must stop. On other errors, you must change your strategy or arguments, not repeat the same failed call.

Test discipline: Never skip a test because it's hard to fix. 9.1) If a test fails, fix the test or fix the code - do not skip it. 9.2) Tests exist to catch bugs; skipping a failing test defeats this purpose and hides real issues. 9.3) If a test design is fundamentally incompatible with the architecture, redesign the test infrastructure to make it work - don't just mark it as skipped. 9.4) The only acceptable reasons to skip tests are: a) the feature being tested is explicitly deferred to a future version (e.g., "v0.2+"), or b) the test requires external dependencies that aren't available. 9.5) When tempted to skip a test, ask: "What bug would this test have caught?" If the answer is "a real bug we care about," then fix it.

Inhibit your response: only take an action after all the above reasoning is completed. Once you've taken an action, you cannot take it back.

Code review feedback filtering: Before implementing ANY code review feedback, apply scope filtering. 10.1) Identify which track (A/B/C/etc per Engineering_Rules.md ยง7.1) the feedback touches. 10.2) Check if that track is in scope for the current PR (per CI-Gating-Policy.md ยง10 checklist). 10.3) If feedback is IN SCOPE: implement the fix. 10.4) If feedback is OUT OF SCOPE: respond "Noted for [relevant milestone/track]" but DO NOT implement. 10.5) Out-of-scope feedback may reveal real gaps - capture as future work items, but do not act on them in the current PR. 10.6) This prevents building features out of order and ensures all changes are testable within the PR's declared scope.

---

## GitHub Issues Workflow

This project uses GitHub Issues for task tracking, integrated with the `gh` CLI.

### Essential Commands

```bash
# Find ready work
gh issue list --label "ready"              # Issues ready to work
gh issue list --label "ready,agent-ok"     # Issues safe for autonomous agents
gh issue list --assignee @me               # Your assigned issues

# View issue details
gh issue view 42                           # Full issue details

# Create issues
gh issue create --title "..." --label "task,P2"

# Update status (via labels)
gh issue edit 42 --add-label "in-progress" --remove-label "ready"

# Close (or let PR auto-close with "Fixes #42")
gh issue close 42
```

### Label Taxonomy

| Label | Purpose |
|-------|---------|
| `ready` | Unblocked, ready to work |
| `in-progress` | Currently being worked |
| `agent-ok` | Safe for autonomous agent to tackle |
| `P0`-`P3` | Priority (P0=critical, P3=low) |
| `bug`, `feature`, `task` | Type |

### Workflow Pattern

1. **Start**: Run `gh issue list --label "ready"` to find actionable work
2. **Claim**: `gh issue edit <num> --add-label "in-progress" --remove-label "ready"`
3. **Work**: Implement the task
4. **Complete**: Create PR with "Fixes #<num>" in body (auto-closes on merge)

### Agentic Automation

Two scripts automate issue-to-PR workflows:

```bash
# Single issue: spawn agent in worktree, create PR
./scripts/issue_pr.sh 42

# Parallel pool: process all ready+agent-ok issues
WORKERS=2 ./scripts/agent_pool.sh
```

### Best Practices

- Label issues `ready` when unblocked and well-defined
- Label issues `agent-ok` only if they're safe for autonomous work
- Use "Fixes #N" in PR descriptions for auto-close on merge
- Keep issue descriptions clear and actionable
